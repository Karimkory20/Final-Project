# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GC8cgHmQrGiC3vhvjUSbwTMZgnX18bRv
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from preprocess import prepare_time_series, create_sequences
import os
import pandas as pd
import json
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split


def load_data(file_path):
    try:
        if file_path.endswith('.xlsx'):
            df = pd.read_excel(file_path)
        else:
            df = pd.read_csv(file_path)

        df['AttackDate'] = pd.to_datetime(df['AttackDate'])
        df = df.sort_values(['AttackDate', 'Country'])
        df['Total_Attack_Percentage'] = df['Total_Attack_Percentage'].apply(
            lambda x: x.split('%')[0] if isinstance(x, str) else x
        )
        df['Total_Attack_Percentage'] = pd.to_numeric(df['Total_Attack_Percentage'], errors='coerce') / 100
        df = df.dropna(subset=['Total_Attack_Percentage', 'Country', 'AttackDate'])
        return df
    except Exception as e:
        print(f"Error loading data: {e}")
        return None


def create_time_series(df, country, target_col='Total_Attack_Percentage'):
    country_df = df[df['Country'] == country].sort_values('AttackDate')
    return country_df[['AttackDate', target_col]].set_index('AttackDate')


def preprocess_data(series, seq_length=10):
    scaler = MinMaxScaler()
    data = scaler.fit_transform(series.values.reshape(-1, 1))
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y), scaler


def create_lstm_model(seq_length):
    """Create and compile LSTM model."""
    model = Sequential([
        LSTM(50, activation='relu', input_shape=(seq_length, 1), return_sequences=True),
        Dropout(0.2),
        LSTM(50, activation='relu'),
        Dropout(0.2),
        Dense(1)
    ])
    
    model.compile(optimizer=Adam(learning_rate=0.001),
                 loss='mse',
                 metrics=['mae'])
    
    return model


def train_lstm_model(df, country, seq_length=10, epochs=50):
    """Train LSTM model for a specific country."""
    print(f"\nTraining LSTM model for {country}...")
    
    # Prepare data
    series = prepare_time_series(df, country)
    X, y, scaler = create_sequences(series, seq_length)
    
    # Split data
    train_size = int(len(X) * 0.8)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    # Create and train model
    model = create_lstm_model(seq_length)
    
    # Train the model
    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=1
    )
    
    # Plot training history
    plt.figure(figsize=(10, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title(f'Model Loss for {country}')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(f'loss_{country.replace(" ", "_")}.png')
    plt.close()
    
    return model, scaler


def generate_predictions(model, scaler, df, country, seq_length=10, days=180):
    """Generate 6-month predictions for a country."""
    print(f"Generating 6-month predictions for {country}...")
    
    # Get the last sequence
    series = prepare_time_series(df, country)
    last_sequence = series.values[-seq_length:]
    
    # Scale the sequence
    scaled_sequence = scaler.transform(last_sequence)
    
    # Generate predictions
    predictions = []
    current_sequence = scaled_sequence.copy()
    
    for _ in range(days):
        # Reshape for prediction
        X = current_sequence.reshape(1, seq_length, 1)
        
        # Predict next value
        next_pred = model.predict(X, verbose=0)
        predictions.append(next_pred[0, 0])
        
        # Update sequence
        current_sequence = np.roll(current_sequence, -1)
        current_sequence[-1] = next_pred
    
    # Inverse transform predictions
    predictions = np.array(predictions).reshape(-1, 1)
    predictions = scaler.inverse_transform(predictions)
    
    # Plot predictions
    plt.figure(figsize=(12, 6))
    plt.plot(range(days), predictions, label='Predicted')
    plt.title(f'6-Month Forecast for {country}')
    plt.xlabel('Days into Future')
    plt.ylabel('Attack Percentage')
    plt.legend()
    plt.grid(True)
    plt.savefig(f'forecast_{country.replace(" ", "_")}.png')
    plt.close()
    
    return predictions.flatten()


def train_model(X_train, y_train):
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    return model


def predict_future(model, last_sequence, scaler, steps=180):
    future_predictions = []
    current_sequence = last_sequence.copy()

    for _ in range(steps):
        next_pred = model.predict(current_sequence.reshape(1, -1))
        future_predictions.append(next_pred[0])
        current_sequence = np.roll(current_sequence, -1)
        current_sequence[-1] = next_pred[0]

    future_predictions = np.array(future_predictions).reshape(-1, 1)
    future_predictions = scaler.inverse_transform(future_predictions)
    return future_predictions.flatten()


def plot_loss(y_true, y_pred, country):
    mse = mean_squared_error(y_true, y_pred)
    plt.figure()
    plt.plot(y_true, label='True')
    plt.plot(y_pred, label='Predicted')
    plt.title(f'Model Performance for {country} (MSE: {mse:.4f})')
    plt.xlabel('Time')
    plt.ylabel('Attack Percentage')
    plt.legend()
    plt.savefig(f'loss_{country.replace(" ", "_")}.png')
    plt.close()


def plot_forecast(future_vals, country):
    days = np.arange(1, len(future_vals)+1)
    plt.figure(figsize=(10, 5))
    plt.plot(days, future_vals, label='Forecasted Attack Percentage')
    plt.title(f'6-Month Forecast for {country}')
    plt.xlabel('Days into Future')
    plt.ylabel('Attack Percentage')
    plt.grid(True)
    plt.legend()
    plt.savefig(f'forecast_{country.replace(" ", "_")}.png')
    plt.close()


if __name__ == "__main__":
    # Test the LSTM model
    from preprocess import load_and_preprocess_data, get_top_10_countries
    
    # Load and preprocess data
    df = load_and_preprocess_data("Data/cleanedd_Attack_file.csv")
    if df is not None:
        # Get top 10 countries
        top_10 = get_top_10_countries(df)
        
        # Dictionary to store predictions for all countries
        all_predictions = {}
        
        # Process each country
        for country in top_10:
            print(f"\nProcessing predictions for {country}...")
            try:
                model, scaler = train_lstm_model(df, country)
                predictions = generate_predictions(model, scaler, df, country)
                # Convert predictions to list for JSON serialization
                predictions_list = predictions.tolist() if hasattr(predictions, 'tolist') else list(predictions)
                all_predictions[country] = predictions_list
                print(f"Generated {len(predictions)} days of predictions for {country}")
            except Exception as e:
                print(f"Error processing {country}: {str(e)}")
                continue

        # Save all predictions
        os.makedirs('web', exist_ok=True)
        with open('web/future_predictions.json', 'w') as f:
            json.dump(all_predictions, f, indent=2)
        print("\nAll predictions saved to web/future_predictions.json")
        
        # Print summary
        print("\nPrediction Summary:")
        for country, preds in all_predictions.items():
            avg_pred = sum(preds) / len(preds)
            print(f"{country}: Average predicted attack percentage = {avg_pred:.2f}%")
